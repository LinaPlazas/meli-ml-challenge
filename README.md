<h1 align="center">Meli ML Chanllenge üöÄ </h1> 

## Resumen: 
El presente proyecto tiene como fin plantear una posible soluci√≥n para el reto t√©cnico planteado, el cual consiste en dise√±ar y construir un sistema que realice las siguientes tareas a partir de diferentes documentos en formato pdf:<br> 

***1. Clasificaci√≥n autom√°tica por tipo de documento:*** <br>

   Cada archivo debe ser clasificado en una de las siguientes categorias: 
   - Contrato
   - Resoluci√≥n
   - Certificado
   - Factura
2. **Detecci√≥n de datos sensibles (PII)**
     
Identifica y resalta informaci√≥n confidencial como:
- Nombres completos  
- N√∫meros de identificaci√≥n  
- Correos electr√≥nicos  
- Tel√©fonos  
- Direcciones
  
3. **Identificaci√≥n de documentos duplicados o similares**
  
Detecta documentos duplicados por medio de un checksum MD5.

4. **Segmentaci√≥n y extracci√≥n de secciones de inter√©s (Opcional)**

Extrae de cada documento la secci√≥n espec√≠fica que contiene requisitos normativos,  
cuando exista, o marca el documento como ‚ÄúNo Aplica‚Äù.

## Arquitectura y dise√±o de la soluci√≥n

El siguiente diagrama resume c√≥mo est√° construida la presente soluci√≥n:

![Arquitectura](images/Arquitectura.png)

### Desarrollo y construcci√≥n de la aplicaci√≥n 

La aplicaci√≥n fue desarrollada en FastAPI y luego construida como una imagen de docker la cual se almacena en Amazon ECR para su posterior despliegue.

  
### Despliegue de la aplicaci√≥n 

En cuanto al despliegue se utiliz√≥ AWS ECS con Fargate como servicio de orquestaci√≥n para ejecutar la imagen en un entorno serverless, asimismo se utiliz√≥ un Load Balancer que permite el acceso externo a la API.

### Servicios externos conectados 

Se utiliza MongoDB como base de datos para almacenar el texto extra√≠do de los documentos, as√≠ como otros procesamientos realizados (clasificaci√≥n de documentos, extracci√≥n de PII, informaci√≥n de duplicados, extracci√≥n de secciones de inter√©s).

Por otro lado, tambi√©n se cuenta con un bucket de S3 para almacenar los documentos utilizados tanto en el entrenamiento del modelo, que se describe m√°s adelante, como en las diferentes pruebas de la aplicaci√≥n.

## Implementaci√≥n detallada de la soluci√≥n

Para el desarrollo de la aplicaci√≥n, se procur√≥ seguir principios de arquitectura limpia, organizando el proyecto en m√≥dulos con responsabilidades definidas. A continuaci√≥n se explicara cada uno de los modulos:

### Extracci√≥n de texto 
Para abordar el problema planteado, el primer paso realizado fue lograr la extracci√≥n de texto de archivos pdf, para esto se utiliz√≥ amazon textract debido a que ofrece una extracci√≥n robusta basada en machine learning,que no solo reconoce texto impreso, sino tambi√©n estructuras complejas como tablas y formularios.

De igual manera para enfrentar el problema de el procesamiento asincronico se utilizo start_document_text_detection, esta opci√≥n permite iniciar m√∫ltiples procesos de extracci√≥n en paralelo sin necesidad de esperar a que cada uno finalice antes de continuar con el siguiente.

Para gestionar este procesamiento concurrente, se implement√≥ una estrategia que permite lanzar varios trabajos de an√°lisis al mismo tiempo, hacer seguimiento de cada uno de ellos de forma no bloqueante, y finalmente recolectar los resultados una vez completados. Una vez obtenidos los textos de los archivos pdf, se almacenan en la base de datos, lo que permite su posterior uso en tareas como clasificaci√≥n autom√°tica, detecci√≥n de informaci√≥n sensible o an√°lisis de secciones normativas.

### Clasificaci√≥n en categorias

#### Pre procesamiento y entrenamiento del modelo

Con el fin de implementar el sistema clasificador de textos, fueron necesarios unos pasos previos al desarrollo del modulo. En primer lugar se recolectaron diferentes archivos pdf con el objetivo de armar un dataset, de esta manera los documentos referentes a contratos, resoluciones y certificados, se obtuvieron del repositorio de datos abiertos de Secop II [Datos abiertos Secop II](https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-II-Contratos-Electr-nicos/jbjy-vk9h/about_data), de igual manera para las facturas, se utilizaron plantillas de ejemplo.

En total se obtuvieron la siguiente cantidad de documentos, la cantidad de paginas variaba por documento, algunos tenian hasta 15 p√°ginas:

Certificados: 49 <br>
Contratos:43 <br>
Resoluciones: 56 <br>
Facturas: 37 <br>

Una vez recolectados los documentos de entrenamiento, se procedi√≥ a construir el dataset en formato tabular, con el fin de utilizarlo como entrada para los modelos,Este proceso se llev√≥ a cabo mediante un notebook de Jupyter, ubicado en la ruta notebooks/create_tabular_dataset.py, la salida fue un archivo CSV que contiene los campos: filename, label (etiqueta correspondiente a la clase del documento) y text (texto extra√≠do del PDF utilizando Amazon Textract) y se encuentra en la ruta notebooks/data/dataset.csv

Una vez obtenido el dataset tabular, se procedi√≥ a realizar diferentes pruebas utilizando modelos de aprendizaje autom√°tico tradicional. Para ello, se implement√≥ una etapa de vectorizaci√≥n del texto puesto que  Los modelos no entienden palabras directamente, por lo cual la vectorizaci√≥n convierte el texto en representaciones num√©ricas que los algoritmos de machine learning pueden procesar. Se inici√≥ con un modelo de regresi√≥n log√≠stica debido a su simplicidad y buen desempe√±o en problemas de clasificaci√≥n de texto. Los datos se dividieron en un 80 % para entrenamiento y un 20 % para validaci√≥n. A continuaci√≥n, se presentan los resultados obtenidos:

![matrizrl1](images/mc_regresion1.png)
![metricas1](images/metricas_regresion1.png)

Aunque los resultados fueron prometedores, se decidi√≥ mejorar el preprocesamiento del texto incorporando una peque√±a etapa de limpieza y tokenizaci√≥n del texto para optimizar la calidad de las caracter√≠sticas extra√≠das. Adem√°s se decidi√≥ evaluar varios modelos de clasificaci√≥n como adicional a la regresi√≥n logistica como Lineal SVM, Random Forest, Multinomial Naive Bayes, con el fin de comparar y elegir el que brindara mejores m√©tricas. A continuaci√≥n se muestran los resultados de cada uno de los modelos con la limpieza de texto realizada

Regresi√≥n Logistica
![matrizrl2](images/mc_regresion2.png)
![metricas2](images/metricas_regresion2.png)

SVM
![matrizsvm](images/mc_SVM.png)
![metricas3](images/metricas_SVM.png)

Random Forest
![matrizrandom](images/mc_randomforest.png)
![metricas4](images/metricas_randomforest.png)

NB
![matriznb](images/mc_NB.png)
![metricas1](images/metricas_NB.png)

Como se puede observar, en t√©rminos generales y para todas las m√©tricas (Accuracy, Precision, Recall y F1-score), el modelo Random Forest alcanz√≥ un desempe√±o cercano al 97%. Por ello, fue seleccionado para su implementaci√≥n en el m√≥dulo de clasificaci√≥n de categor√≠as.

#### Implementaci√≥n modulo clasificador

Una vez obtenido el modelo clasificador, se desarroll√≥ el m√≥dulo encargado de determinar la categor√≠a que mejor se ajusta al documento. Para ello, se consulta en la base de datos el texto extra√≠do de los PDFs y se realiza la clasificaci√≥n correspondiente. Finalmente, el m√≥dulo almacena dos campos: la categor√≠a asignada y los scores, es decir, los puntajes de probabilidad asociados a cada una de las categor√≠as.
   
